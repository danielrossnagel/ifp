{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c50108-7ebe-441f-8e5b-3555c2ebf165",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'learning_to_simulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20428/2815276578.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlearning_to_simulate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreading_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlearning_to_simulate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'learning_to_simulate'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# This is the working directory. This is needed to import from learning_to_simulate\n",
    "os.chdir('C:/OneDrive/Studium/Master/IFP_Integriertes_Forschungsprojekt/Learning_to_Simulate_work') \n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from learning_to_simulate import reading_utils\n",
    "from learning_to_simulate import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864aeae3-d7a0-4e9e-a3fb-70a7aed9d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(data_path):\n",
    "    with open(os.path.join('C:/OneDrive/Studium/Master/IFP_Integriertes_Forschungsprojekt/Learning_to_Simulate_work/datasets/WaterDropSample/metadata.json'), 'rt') as fp:\n",
    "        return json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc95ee0-d721-477c-a38b-82fbc6f8a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_trajectory(context, features, window_length=7):\n",
    "  \"\"\"Splits trajectory into sliding windows.\"\"\"\n",
    "  # Our strategy is to make sure all the leading dimensions are the same size,\n",
    "  # then we can use from_tensor_slices.\n",
    "\n",
    "  trajectory_length = features['position'].get_shape().as_list()[0]\n",
    "\n",
    "  # We then stack window_length position changes so the final\n",
    "  # trajectory length will be - window_length +1 (the 1 to make sure we get\n",
    "  # the last split).\n",
    "  input_trajectory_length = trajectory_length - window_length + 1\n",
    "\n",
    "  model_input_features = {}\n",
    "  # Prepare the context features per step.\n",
    "  model_input_features['particle_type'] = tf.tile(\n",
    "      tf.expand_dims(context['particle_type'], axis=0),\n",
    "      [input_trajectory_length, 1])\n",
    "\n",
    "  if 'step_context' in features:\n",
    "    global_stack = []\n",
    "    for idx in range(input_trajectory_length):\n",
    "      global_stack.append(features['step_context'][idx:idx + window_length])\n",
    "    model_input_features['step_context'] = tf.stack(global_stack)\n",
    "\n",
    "  pos_stack = []\n",
    "  for idx in range(input_trajectory_length):\n",
    "    pos_stack.append(features['position'][idx:idx + window_length])\n",
    "  # Get the corresponding positions\n",
    "  model_input_features['position'] = tf.stack(pos_stack)\n",
    "\n",
    "  return tf.data.Dataset.from_tensor_slices(model_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029d99d9-c3f7-4222-b201-dea6918c0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(x, encoded_dtype):\n",
    "  if len(x) == 1:\n",
    "    out = np.frombuffer(x[0].numpy(), dtype=encoded_dtype)\n",
    "  else:\n",
    "    out = []\n",
    "    for el in x:\n",
    "      out.append(np.frombuffer(el.numpy(), dtype=encoded_dtype))\n",
    "  out = tf.convert_to_tensor(np.array(out))\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c364ce22-45ee-4f9c-a0d3-0f830cd7e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a description of the features.\n",
    "_FEATURE_DESCRIPTION = {\n",
    "    'position': tf.io.VarLenFeature(tf.string),\n",
    "}\n",
    "\n",
    "_FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT = _FEATURE_DESCRIPTION.copy()\n",
    "_FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT['step_context'] = tf.io.VarLenFeature(\n",
    "    tf.string)\n",
    "\n",
    "_FEATURE_DTYPES = {\n",
    "    'position': {\n",
    "        'in': np.float32,\n",
    "        'out': tf.float32\n",
    "    },\n",
    "    'step_context': {\n",
    "        'in': np.float32,\n",
    "        'out': tf.float32\n",
    "    }\n",
    "}\n",
    "\n",
    "_CONTEXT_FEATURES = {\n",
    "    'key': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    'particle_type': tf.io.VarLenFeature(tf.string)\n",
    "}\n",
    "\n",
    "def parse_serialized_simulation_example(example_proto, metadata):\n",
    "  \"\"\"Parses a serialized simulation tf.SequenceExample.\n",
    "\n",
    "  Args:\n",
    "    example_proto: A string encoding of the tf.SequenceExample proto.\n",
    "    metadata: A dict of metadata for the dataset.\n",
    "\n",
    "  Returns:\n",
    "    context: A dict, with features that do not vary over the trajectory.\n",
    "    parsed_features: A dict of tf.Tensors representing the parsed examples\n",
    "      across time, where axis zero is the time axis.\n",
    "\n",
    "  \"\"\"\n",
    "  if 'context_mean' in metadata:\n",
    "    feature_description = _FEATURE_DESCRIPTION_WITH_GLOBAL_CONTEXT\n",
    "  else:\n",
    "    feature_description = _FEATURE_DESCRIPTION\n",
    "  context, parsed_features = tf.io.parse_single_sequence_example(example_proto,context_features=_CONTEXT_FEATURES,\n",
    "                                                                 sequence_features=feature_description)\n",
    "  #print(feature_description, context, parsed_features)\n",
    "  for feature_key, item in parsed_features.items():\n",
    "    convert_fn = functools.partial(convert_to_tensor, encoded_dtype=_FEATURE_DTYPES[feature_key]['in'])\n",
    "    parsed_features[feature_key] = tf.py_function(convert_fn, inp=[item.values], Tout=_FEATURE_DTYPES[feature_key]['out'])\n",
    "  # There is an extra frame at the beginning so we can calculate pos change\n",
    "  # for all frames used in the paper.\n",
    "  position_shape = [metadata['sequence_length'] + 1, -1, metadata['dim']]\n",
    "\n",
    "  # Reshape positions to correct dim:\n",
    "  parsed_features['position'] = tf.reshape(parsed_features['position'],\n",
    "                                           position_shape)\n",
    "  # Set correct shapes of the remaining tensors.\n",
    "  sequence_length = metadata['sequence_length'] + 1\n",
    "  if 'context_mean' in metadata:\n",
    "    context_feat_len = len(metadata['context_mean'])\n",
    "    parsed_features['step_context'] = tf.reshape(\n",
    "        parsed_features['step_context'],\n",
    "        [sequence_length, context_feat_len])\n",
    "  # Decode particle type explicitly\n",
    "  context['particle_type'] = tf.py_function(\n",
    "      functools.partial(convert_fn, encoded_dtype=np.int64),\n",
    "      inp=[context['particle_type'].values],\n",
    "      Tout=[tf.int64])\n",
    "  context['particle_type'] = tf.reshape(context['particle_type'], [-1])\n",
    "  return context, parsed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02fa58af-c9e7-4093-b656-508fe4445db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(tensor_dict):\n",
    "  \"\"\"Prepares a single stack of inputs by calculating inputs and targets.\n",
    "\n",
    "  Computes n_particles_per_example, which is a tensor that contains information\n",
    "  about how to partition the axis - i.e. which nodes belong to which graph.\n",
    "\n",
    "  Adds a batch axis to `n_particles_per_example` and `step_context` so they can\n",
    "  later be batched using `batch_concat`. This batch will be the same as if the\n",
    "  elements had been batched via stacking.\n",
    "\n",
    "  Note that all other tensors have a variable size particle axis,\n",
    "  and in this case they will simply be concatenated along that\n",
    "  axis.\n",
    "\n",
    "\n",
    "\n",
    "  Args:\n",
    "    tensor_dict: A dict of tensors containing positions, and step context (\n",
    "    if available).\n",
    "\n",
    "  Returns:\n",
    "    A tuple of input features and target positions.\n",
    "\n",
    "  \"\"\"\n",
    "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
    "  # expects [num_particles, sequence_length, dim].\n",
    "  pos = tensor_dict['position']\n",
    "  pos = tf.transpose(pos, perm=[1, 0, 2])\n",
    "\n",
    "  # The target position is the final step of the stack of positions.\n",
    "  target_position = pos[:, -1]\n",
    "\n",
    "  # Remove the target from the input.\n",
    "  tensor_dict['position'] = pos[:, :-1]\n",
    "\n",
    "  # Compute the number of particles per example.\n",
    "  num_particles = tf.shape(pos)[0]\n",
    "  # Add an extra dimension for stacking via concat.\n",
    "  tensor_dict['n_particles_per_example'] = num_particles[tf.newaxis]\n",
    "\n",
    "  if 'step_context' in tensor_dict:\n",
    "    # Take the input global context. We have a stack of global contexts,\n",
    "    # and we take the penultimate since the final is the target.\n",
    "    tensor_dict['step_context'] = tensor_dict['step_context'][-2]\n",
    "    # Add an extra dimension for stacking via concat.\n",
    "    tensor_dict['step_context'] = tensor_dict['step_context'][tf.newaxis]\n",
    "  return tensor_dict, target_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2da01bb-af8b-48a5-ada2-05551b0cd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rollout_inputs(context, features):\n",
    "  \"\"\"Prepares an inputs trajectory for rollout.\"\"\"\n",
    "  out_dict = {**context}\n",
    "  # Position is encoded as [sequence_length, num_particles, dim] but the model\n",
    "  # expects [num_particles, sequence_length, dim].\n",
    "  pos = tf.transpose(features['position'], [1, 0, 2])\n",
    "  # The target position is the final step of the stack of positions.\n",
    "  target_position = pos[:, -1]\n",
    "  # Remove the target from the input.\n",
    "  out_dict['position'] = pos[:, :-1]\n",
    "  # Compute the number of nodes\n",
    "  out_dict['n_particles_per_example'] = [tf.shape(pos)[0]]\n",
    "  if 'step_context' in features:\n",
    "    out_dict['step_context'] = features['step_context']\n",
    "  out_dict['is_trajectory'] = tf.constant([True], tf.bool)\n",
    "  return out_dict, target_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5d0c01-5984-4ee0-b8c6-ec91f036d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_dict: {'particle_type': <tf.Tensor: id=4093, shape=(295,), dtype=int64, numpy=\n",
      "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64)>, 'key': <tf.Tensor: id=4091, shape=(), dtype=int64, numpy=0>, 'position': <tf.Tensor: id=4094, shape=(295, 1000, 2), dtype=float32, numpy=\n",
      "array([[[0.65348333, 0.3366845 ],\n",
      "        [0.65348333, 0.33659106],\n",
      "        [0.65348333, 0.3364364 ],\n",
      "        ...,\n",
      "        [0.8152361 , 0.10710638],\n",
      "        [0.8151884 , 0.10710894],\n",
      "        [0.81514347, 0.10711136]],\n",
      "\n",
      "       [[0.65415716, 0.3229508 ],\n",
      "        [0.65415716, 0.32285747],\n",
      "        [0.65415716, 0.32270283],\n",
      "        ...,\n",
      "        [0.8010312 , 0.1060667 ],\n",
      "        [0.8009922 , 0.10606938],\n",
      "        [0.80095625, 0.10607237]],\n",
      "\n",
      "       [[0.6528629 , 0.3064468 ],\n",
      "        [0.6528629 , 0.30635348],\n",
      "        [0.6528629 , 0.30619895],\n",
      "        ...,\n",
      "        [0.8327564 , 0.10686205],\n",
      "        [0.8327087 , 0.10685946],\n",
      "        [0.8326624 , 0.10685704]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.6032004 , 0.203077  ],\n",
      "        [0.6032004 , 0.20298368],\n",
      "        [0.6032004 , 0.20282905],\n",
      "        ...,\n",
      "        [0.56442374, 0.09820116],\n",
      "        [0.5647009 , 0.09820149],\n",
      "        [0.56497234, 0.09820182]],\n",
      "\n",
      "       [[0.6489395 , 0.45497558],\n",
      "        [0.6489395 , 0.4548821 ],\n",
      "        [0.6489395 , 0.45472723],\n",
      "        ...,\n",
      "        [0.50549334, 0.11086477],\n",
      "        [0.5061179 , 0.11087445],\n",
      "        [0.5067387 , 0.11088573]],\n",
      "\n",
      "       [[0.5779556 , 0.47371852],\n",
      "        [0.5779556 , 0.47362506],\n",
      "        [0.5779556 , 0.47347033],\n",
      "        ...,\n",
      "        [0.4243241 , 0.1144923 ],\n",
      "        [0.42501888, 0.11448085],\n",
      "        [0.42571098, 0.11446922]]], dtype=float32)>, 'n_particles_per_example': <tf.Tensor: id=4092, shape=(1,), dtype=int32, numpy=array([295])>, 'is_trajectory': <tf.Tensor: id=4090, shape=(1,), dtype=bool, numpy=array([ True])>} \n",
      "\n",
      "target_position: [[0.8151003  0.10711416]\n",
      " [0.8009222  0.10607563]\n",
      " [0.83261764 0.1068546 ]\n",
      " [0.6630566  0.10649024]\n",
      " [0.71692085 0.108978  ]\n",
      " [0.6268878  0.10891214]\n",
      " [0.80150694 0.1049269 ]\n",
      " [0.76083714 0.10743595]\n",
      " [0.64221174 0.10875682]\n",
      " [0.82369393 0.10415845]\n",
      " [0.80938464 0.10471849]\n",
      " [0.7378612  0.1087147 ]\n",
      " [0.74856216 0.10867728]\n",
      " [0.7180751  0.10617451]\n",
      " [0.585878   0.10605139]\n",
      " [0.5550424  0.10880738]\n",
      " [0.5080531  0.10600967]\n",
      " [0.5580391  0.1119367 ]\n",
      " [0.5120274  0.10827385]\n",
      " [0.63005054 0.11196542]\n",
      " [0.5829548  0.10831817]\n",
      " [0.69578236 0.10970195]\n",
      " [0.79240066 0.11150317]\n",
      " [0.5736643  0.1117522 ]\n",
      " [0.7844986  0.10528424]\n",
      " [0.6658013  0.10567635]\n",
      " [0.5782879  0.10580482]\n",
      " [0.6386896  0.10235406]\n",
      " [0.6084818  0.10215248]\n",
      " [0.4927483  0.10780104]\n",
      " [0.62471324 0.11417814]\n",
      " [0.5695276  0.10714171]\n",
      " [0.67194104 0.11366171]\n",
      " [0.8672872  0.11440462]\n",
      " [0.6539692  0.11615467]\n",
      " [0.5626069  0.11015633]\n",
      " [0.62497413 0.11729293]\n",
      " [0.57840955 0.11054812]\n",
      " [0.66377515 0.10488048]\n",
      " [0.5131131  0.10731149]\n",
      " [0.6295571  0.10298426]\n",
      " [0.50672287 0.09997092]\n",
      " [0.2051709  0.10458943]\n",
      " [0.35340226 0.0992444 ]\n",
      " [0.30108923 0.10320488]\n",
      " [0.20993373 0.10406716]\n",
      " [0.6389879  0.1038567 ]\n",
      " [0.8163684  0.11475993]\n",
      " [0.80888706 0.1092463 ]\n",
      " [0.70920074 0.10469938]\n",
      " [0.75382245 0.100176  ]\n",
      " [0.59509945 0.10605074]\n",
      " [0.5860286  0.10563772]\n",
      " [0.7681153  0.1068644 ]\n",
      " [0.48642585 0.10043968]\n",
      " [0.6022643  0.10489041]\n",
      " [0.77637887 0.11359063]\n",
      " [0.48382482 0.10838944]\n",
      " [0.71802044 0.1148752 ]\n",
      " [0.59184635 0.10545518]\n",
      " [0.62943983 0.10211949]\n",
      " [0.6385821  0.10153573]\n",
      " [0.5477696  0.10379887]\n",
      " [0.28091946 0.10364366]\n",
      " [0.26202753 0.10352548]\n",
      " [0.43238193 0.10043286]\n",
      " [0.43566307 0.09970881]\n",
      " [0.5960995  0.10384022]\n",
      " [0.45645878 0.10780595]\n",
      " [0.26507998 0.10976681]\n",
      " [0.5654224  0.11655489]\n",
      " [0.27493268 0.11012886]\n",
      " [0.72624767 0.10611123]\n",
      " [0.52253264 0.10531328]\n",
      " [0.44650164 0.11027041]\n",
      " [0.44071788 0.10782483]\n",
      " [0.23439206 0.11085801]\n",
      " [0.39660445 0.11628612]\n",
      " [0.60794914 0.11861762]\n",
      " [0.4693701  0.11106542]\n",
      " [0.5622079  0.10112825]\n",
      " [0.502652   0.10259303]\n",
      " [0.6181487  0.10823013]\n",
      " [0.2735367  0.10436672]\n",
      " [0.43416053 0.10084603]\n",
      " [0.4966544  0.11089044]\n",
      " [0.44314802 0.10542524]\n",
      " [0.4850456  0.11053712]\n",
      " [0.4768311  0.11096472]\n",
      " [0.36939183 0.10796157]\n",
      " [0.40628576 0.1009681 ]\n",
      " [0.32442173 0.10099225]\n",
      " [0.38902658 0.1020496 ]\n",
      " [0.53055906 0.10210698]\n",
      " [0.2674592  0.11054847]\n",
      " [0.28252104 0.10587994]\n",
      " [0.24261852 0.10929099]\n",
      " [0.33566698 0.10382046]\n",
      " [0.220171   0.10652474]\n",
      " [0.66210407 0.13076274]\n",
      " [0.5952405  0.12491953]\n",
      " [0.22641559 0.11124195]\n",
      " [0.8322299  0.11851162]\n",
      " [0.7550205  0.11503887]\n",
      " [0.3949093  0.10566509]\n",
      " [0.4119585  0.10604107]\n",
      " [0.439292   0.10394335]\n",
      " [0.218761   0.1007711 ]\n",
      " [0.2495902  0.11236326]\n",
      " [0.23923282 0.10131983]\n",
      " [0.50661165 0.12060442]\n",
      " [0.47624987 0.10354301]\n",
      " [0.87812126 0.11883678]\n",
      " [0.50596064 0.09891357]\n",
      " [0.6409082  0.10557724]\n",
      " [0.33658263 0.11288896]\n",
      " [0.35459796 0.1126078 ]\n",
      " [0.23397529 0.11212419]\n",
      " [0.18141612 0.10370394]\n",
      " [0.19972219 0.10369264]\n",
      " [0.619913   0.11824014]\n",
      " [0.38736743 0.10633703]\n",
      " [0.49974018 0.11120982]\n",
      " [0.6847399  0.11509637]\n",
      " [0.39960632 0.10546972]\n",
      " [0.2199511  0.10098544]\n",
      " [0.69729596 0.11219884]\n",
      " [0.37862712 0.10134133]\n",
      " [0.8350025  0.10458741]\n",
      " [0.73761433 0.11473877]\n",
      " [0.81809986 0.10308989]\n",
      " [0.8582062  0.10955601]\n",
      " [0.77835447 0.10750038]\n",
      " [0.74469703 0.10110754]\n",
      " [0.2736707  0.10848594]\n",
      " [0.3343313  0.10650167]\n",
      " [0.41027373 0.1160983 ]\n",
      " [0.7038284  0.11543343]\n",
      " [0.67005384 0.12119969]\n",
      " [0.5374972  0.11949533]\n",
      " [0.28185585 0.10022119]\n",
      " [0.18973266 0.10596242]\n",
      " [0.17404298 0.11216645]\n",
      " [0.30295366 0.11368797]\n",
      " [0.8395348  0.11901114]\n",
      " [0.67521065 0.12098804]\n",
      " [0.60069036 0.11946131]\n",
      " [0.5618343  0.1211533 ]\n",
      " [0.5722946  0.11914922]\n",
      " [0.6794492  0.10415082]\n",
      " [0.60171276 0.10593228]\n",
      " [0.46326235 0.10130414]\n",
      " [0.85278386 0.10698091]\n",
      " [0.83719134 0.10197135]\n",
      " [0.81157196 0.10185602]\n",
      " [0.77856296 0.10178921]\n",
      " [0.6391464  0.10040894]\n",
      " [0.7414162  0.11902592]\n",
      " [0.22982457 0.11543944]\n",
      " [0.6546369  0.10184309]\n",
      " [0.86646384 0.1012558 ]\n",
      " [0.87483525 0.108202  ]\n",
      " [0.5134223  0.10331492]\n",
      " [0.86769956 0.10471138]\n",
      " [0.5618278  0.11930219]\n",
      " [0.18115813 0.10678288]\n",
      " [0.5895826  0.09958521]\n",
      " [0.69784516 0.10352991]\n",
      " [0.8389157  0.10034099]\n",
      " [0.28339997 0.11284869]\n",
      " [0.27664813 0.11259524]\n",
      " [0.6290549  0.12435294]\n",
      " [0.17756614 0.1137431 ]\n",
      " [0.16353534 0.10792866]\n",
      " [0.21832824 0.11243528]\n",
      " [0.3207695  0.11537387]\n",
      " [0.37490258 0.11575571]\n",
      " [0.13596347 0.11182133]\n",
      " [0.14511636 0.10436468]\n",
      " [0.1540824  0.11797129]\n",
      " [0.1602378  0.11567107]\n",
      " [0.42946535 0.11510809]\n",
      " [0.6803057  0.11848274]\n",
      " [0.72931916 0.11903511]\n",
      " [0.6560056  0.12868638]\n",
      " [0.66674554 0.12247745]\n",
      " [0.5872343  0.12308313]\n",
      " [0.6676013  0.11964159]\n",
      " [0.20053227 0.11500987]\n",
      " [0.5594114  0.1266552 ]\n",
      " [0.17303291 0.10560673]\n",
      " [0.15993208 0.10677244]\n",
      " [0.7030235  0.10109469]\n",
      " [0.7238207  0.10052754]\n",
      " [0.6249147  0.12111464]\n",
      " [0.7941519  0.11470761]\n",
      " [0.8906938  0.09663663]\n",
      " [0.4449345  0.11755481]\n",
      " [0.12463661 0.11645468]\n",
      " [0.22733009 0.11240439]\n",
      " [0.19399244 0.11497356]\n",
      " [0.12449742 0.11850195]\n",
      " [0.71708614 0.12240721]\n",
      " [0.40223056 0.09831733]\n",
      " [0.17055276 0.114436  ]\n",
      " [0.16449709 0.11441234]\n",
      " [0.1320711  0.11626081]\n",
      " [0.5345046  0.11203354]\n",
      " [0.7434416  0.11378299]\n",
      " [0.829119   0.09922813]\n",
      " [0.13766575 0.12020024]\n",
      " [0.71049833 0.11584701]\n",
      " [0.7652183  0.11921175]\n",
      " [0.6475146  0.12066821]\n",
      " [0.47777987 0.11840448]\n",
      " [0.35872477 0.10278591]\n",
      " [0.39692292 0.10320729]\n",
      " [0.850528   0.12058248]\n",
      " [0.5967115  0.12235197]\n",
      " [0.5930838  0.11533323]\n",
      " [0.8800933  0.11912408]\n",
      " [0.3521202  0.10597891]\n",
      " [0.88970715 0.10589837]\n",
      " [0.8880357  0.11860406]\n",
      " [0.8989299  0.10813047]\n",
      " [0.7073408  0.11413672]\n",
      " [0.75050193 0.12260156]\n",
      " [0.4278682  0.10962667]\n",
      " [0.6376282  0.11535036]\n",
      " [0.42195904 0.10879102]\n",
      " [0.23452088 0.09900125]\n",
      " [0.6853038  0.10237087]\n",
      " [0.50406086 0.11690535]\n",
      " [0.44283053 0.11165018]\n",
      " [0.45762488 0.11413234]\n",
      " [0.31801522 0.10521385]\n",
      " [0.8428475  0.09551189]\n",
      " [0.8524255  0.0956108 ]\n",
      " [0.8565352  0.10126681]\n",
      " [0.6911565  0.10055277]\n",
      " [0.701982   0.12221875]\n",
      " [0.7981492  0.12009165]\n",
      " [0.14443773 0.10544161]\n",
      " [0.15704955 0.10209166]\n",
      " [0.13721469 0.10287701]\n",
      " [0.12777856 0.10634332]\n",
      " [0.81147885 0.1211784 ]\n",
      " [0.6371575  0.11785975]\n",
      " [0.621414   0.12177138]\n",
      " [0.32594767 0.10668245]\n",
      " [0.12106095 0.11391634]\n",
      " [0.15835677 0.10039818]\n",
      " [0.11831129 0.09917399]\n",
      " [0.11628929 0.10458972]\n",
      " [0.12763992 0.09664628]\n",
      " [0.8428657  0.11544964]\n",
      " [0.54103804 0.1142775 ]\n",
      " [0.34270647 0.10654362]\n",
      " [0.32361254 0.1106387 ]\n",
      " [0.36175063 0.10561943]\n",
      " [0.3275448  0.1072171 ]\n",
      " [0.16781071 0.09892403]\n",
      " [0.84007215 0.09537729]\n",
      " [0.15371849 0.09783483]\n",
      " [0.37943408 0.10984061]\n",
      " [0.4008158  0.11045624]\n",
      " [0.6908081  0.11495939]\n",
      " [0.53761107 0.12202917]\n",
      " [0.3766401  0.11123908]\n",
      " [0.5323692  0.11417287]\n",
      " [0.7649193  0.10208123]\n",
      " [0.3656272  0.11244986]\n",
      " [0.33428377 0.11007616]\n",
      " [0.7740823  0.11658911]\n",
      " [0.34381858 0.11147149]\n",
      " [0.11815175 0.09559922]\n",
      " [0.10403025 0.10895041]\n",
      " [0.383879   0.11323147]\n",
      " [0.10946865 0.11383331]\n",
      " [0.24486394 0.1055216 ]\n",
      " [0.45294303 0.11649974]\n",
      " [0.6940965  0.11253923]\n",
      " [0.10805313 0.09694782]\n",
      " [0.28998837 0.10962405]\n",
      " [0.6004728  0.11470469]\n",
      " [0.48885047 0.11725519]\n",
      " [0.4289517  0.11457172]\n",
      " [0.10398936 0.09835099]\n",
      " [0.139544   0.09941   ]\n",
      " [0.24033855 0.10608385]\n",
      " [0.29297322 0.10812437]\n",
      " [0.6864516  0.1010665 ]\n",
      " [0.5652377  0.09820223]\n",
      " [0.50735444 0.11089735]\n",
      " [0.42640078 0.11445841]] \n",
      "\n",
      "out_dict: {'particle_type': <tf.Tensor: id=8111, shape=(803,), dtype=int64, numpy=\n",
      "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int64)>, 'key': <tf.Tensor: id=8109, shape=(), dtype=int64, numpy=1>, 'position': <tf.Tensor: id=8112, shape=(803, 1000, 2), dtype=float32, numpy=\n",
      "array([[[0.36829928, 0.47826713],\n",
      "        [0.36829928, 0.47817367],\n",
      "        [0.36829928, 0.47801882],\n",
      "        ...,\n",
      "        [0.47197908, 0.12570707],\n",
      "        [0.47228214, 0.12561119],\n",
      "        [0.47258654, 0.125516  ]],\n",
      "\n",
      "       [[0.35545436, 0.48095435],\n",
      "        [0.35545436, 0.48086077],\n",
      "        [0.35545436, 0.480706  ],\n",
      "        ...,\n",
      "        [0.6151307 , 0.12171102],\n",
      "        [0.61562467, 0.12169658],\n",
      "        [0.61611503, 0.12168135]],\n",
      "\n",
      "       [[0.35497558, 0.47183245],\n",
      "        [0.35497558, 0.47173908],\n",
      "        [0.35497558, 0.47158432],\n",
      "        ...,\n",
      "        [0.6640693 , 0.13675877],\n",
      "        [0.664816  , 0.13672884],\n",
      "        [0.6655659 , 0.13669989]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.23795559, 0.60371864],\n",
      "        [0.23795559, 0.6036252 ],\n",
      "        [0.23795559, 0.6034704 ],\n",
      "        ...,\n",
      "        [0.27457014, 0.11938109],\n",
      "        [0.27419722, 0.11936539],\n",
      "        [0.27382258, 0.11934919]],\n",
      "\n",
      "       [[0.26486164, 0.6258969 ],\n",
      "        [0.26486164, 0.62580365],\n",
      "        [0.26486164, 0.62564903],\n",
      "        ...,\n",
      "        [0.32604086, 0.14153345],\n",
      "        [0.3257185 , 0.14140263],\n",
      "        [0.32540122, 0.14127024]],\n",
      "\n",
      "       [[0.44359732, 0.62220234],\n",
      "        [0.44359732, 0.6221091 ],\n",
      "        [0.44359732, 0.6219545 ],\n",
      "        ...,\n",
      "        [0.14190646, 0.13789605],\n",
      "        [0.14177164, 0.1379784 ],\n",
      "        [0.14163297, 0.13806376]]], dtype=float32)>, 'n_particles_per_example': <tf.Tensor: id=8110, shape=(1,), dtype=int32, numpy=array([803])>, 'is_trajectory': <tf.Tensor: id=8108, shape=(1,), dtype=bool, numpy=array([ True])>} \n",
      "\n",
      "target_position: [[0.4728961  0.12542146]\n",
      " [0.61660576 0.1216645 ]\n",
      " [0.6663183  0.13667403]\n",
      " ...\n",
      " [0.27344546 0.11933127]\n",
      " [0.32508746 0.14113845]\n",
      " [0.14149104 0.13815169]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "    data_path = ['C:/OneDrive/Studium/Master/IFP_Integriertes_Forschungsprojekt/Learning_to_Simulate_work/datasets/WaterDropSample']\n",
    "    filenames = ['C:/OneDrive/Studium/Master/IFP_Integriertes_Forschungsprojekt/Learning_to_Simulate_work/datasets/WaterDropSample/test.tfrecord']\n",
    "\n",
    "    metadata = read_metadata(data_path)\n",
    "    ds = tf.data.TFRecordDataset(filenames)\n",
    "    ds = ds.map(functools.partial(parse_serialized_simulation_example, metadata=metadata))\n",
    "    ds = ds.map(prepare_rollout_inputs)\n",
    "    \n",
    "    for out_dict, target_position in ds.take(-1): # ds.take(-1) for all elements\n",
    "        print(\"out_dict: {} \\n\".format(out_dict))\n",
    "        print(\"target_position: {} \\n\".format(target_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948cec8-63cf-4220-8e45-f3340c0f852d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
